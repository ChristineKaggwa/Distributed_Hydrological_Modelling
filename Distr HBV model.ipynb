{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ede1f43",
   "metadata": {},
   "source": [
    "# DISTRIBUTED HBV MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0b283d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "#Working with masked array\n",
    "import numpy.ma as ma\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d65e285",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import rasterio\n",
    "import rioxarray\n",
    "#Projecting the files\n",
    "import cartopy.crs as ccrs  # projection\n",
    "\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, LineString, Polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb2434d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xesmf as xe    #For regridding climate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "967c26cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Library to compute flow directions\n",
    "import pyflwdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5065b9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cliping netcdf file\n",
    "\n",
    "from shapely.geometry import mapping\n",
    "import geopandas as gpd  #for reading the shapefile\n",
    "import regionmask  #For masking dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4827c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "from matplotlib.colors import LinearSegmentedColormap, ListedColormap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3dddf5",
   "metadata": {},
   "source": [
    "## Reading DEM file and Sub-basin shapefiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f67c387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Dem for oulu catchment \n",
    "dem= xr.open_dataset(r\"path\\Dem.tif\", engine=\"rasterio\")\n",
    "\n",
    "dem= dem.rename({'band_data': 'elevtn'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "295816c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "shp1= gpd.read_file(r\"path\\subcat1.shp\")\n",
    "shp2= gpd.read_file(r\"path\\subcat2.shp\")\n",
    "shp3= gpd.read_file(r\"path\\subcat3.shp\")\n",
    "shp4= gpd.read_file(r\"path\\subcat4.shp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e92da0",
   "metadata": {},
   "source": [
    "## Creating a function to define a subbasin dem:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d3c9b8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip(cm, shp):\n",
    "    cm = cm.rename({'lat':'y', 'lon':'x'}) # Specifiying the coordinate system\n",
    "    cm.rio.write_crs(\"EPSG:4326\",inplace= True)\n",
    "    \n",
    "    cm_fin= cm.rio.clip(shp.geometry.apply(mapping), shp.crs, all_touched= True, drop= True)\n",
    "    #cm_fin= cm.rio.clip(shp.geometry.apply(mapping), shp.crs)\n",
    "    \n",
    "    cm_fin= cm_fin.rename({'y':'lat', 'x':'lon'})\n",
    "    return cm_fin\n",
    "\n",
    "def clip2(cm, shp):\n",
    "    cm = cm.rename({'lat':'y', 'lon':'x'}) # Specifiying the coordinate system\n",
    "    cm.rio.write_crs(\"EPSG:3067\",inplace= True)\n",
    "    \n",
    "    #cm_fin= cm.rio.clip(shp.geometry.apply(mapping), shp.crs, all_touched= True, drop= True)\n",
    "    cm_fin= cm.rio.clip(shp.geometry.apply(mapping), shp.crs)\n",
    "    \n",
    "    cm_fin= cm_fin.rename({'y':'lat', 'x':'lon'})\n",
    "    return cm_fin\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce78dc51",
   "metadata": {},
   "source": [
    "# HBV ROUTINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14c9099",
   "metadata": {},
   "outputs": [],
   "source": [
    "#readding input data\n",
    "forcing = xr.open_dataset(r\"path*.nc\")\n",
    "\n",
    "#Writng the coordinate system of the input data\n",
    "forcing = forcing.rio.write_crs(\"EPSG: 3067\")\n",
    "\n",
    "#Slicing data \n",
    "forcing_20= forcing.sel(time=slice('1990-01-01', '2022-12-31'))\n",
    "forcing_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0bf67ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input data\n",
    "ds_oul= forcing_20\n",
    "#Creating arrays and masking them \n",
    "# Numpy array from\n",
    "\n",
    "prec= np.array(ds_oul.pr)\n",
    "\n",
    "temp= np.array(ds_oul.tas)\n",
    "\n",
    "evap= np.array(ds_oul.ET0) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c7a721",
   "metadata": {},
   "source": [
    "### HBV Confined Parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfaa9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Area = 1 #km/2\n",
    "LA= 0.1 # Lake percentage in decimals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffa4ff5",
   "metadata": {},
   "source": [
    "### HBV Model Paramters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "76d10447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correction for rain and temperature\n",
    "Pcorr= 1 # Precipitatiot correction\n",
    "Scorr = 1 # snow correction\n",
    "Pgrad= float(0.5) # Precipitation lapse rate (%/ 100m)\n",
    "Tgrad= 0.65  #Temperature lapse rate, wet day (ºC/100 m)\n",
    "Tx = 0 # Threshold temperature for rain and snow \n",
    "\n",
    "\n",
    "#Model paramters for snow\n",
    "Ts= -1 # \n",
    "CX=  3 # Degree day factor\n",
    "CFR= 0.01\n",
    "CPRO = 0.1\n",
    "\n",
    "#Model parameters for soil\n",
    "FC= 50 # Field Capacity \n",
    "LP = 0.8*FC # Threshold paramter to reduce evaporation\n",
    "Beta = 2\n",
    "\n",
    "#Upper tank\n",
    "K1=  0.05 # Slow drainage \n",
    "K2= 0.45 #0.053# Fast drainage\n",
    "UZ1 = 40 # Threshold for fast response \n",
    "PERC= 1 # Percolation\n",
    "\n",
    "#Lower tank\n",
    "KLZ=  0.01 #Drainage cofficient for lower basin 0.005\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c8a838d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating empty array for the different states \n",
    "#Defining the snow routine\n",
    "\n",
    "SN=  np.zeros_like(prec) #Dry snow pack\n",
    "Prain= np.zeros_like(prec) # Precipitation as Rain\n",
    "Psnow= np.zeros_like(prec) # Precipitation as snow\n",
    "SMLT= np.zeros_like(prec) #Snow melt \n",
    "SR= np.zeros_like(prec) #Refreeze\n",
    "ST=  np.zeros_like(prec)#Free water in the snow pack\n",
    "INSOIL= np.zeros_like(prec) # To the soil routine\n",
    "SW= np.zeros_like(prec) # Liquid water in snow\n",
    "\n",
    "#Defining the soil routine \n",
    "dUZ= np.zeros_like(prec)\n",
    "EA = np.zeros_like(prec)\n",
    "SM= np.zeros_like(prec)\n",
    "\n",
    "\n",
    "#Defining the upper tank and lower tank routines\n",
    "#Upper tank\n",
    "UZ= np.zeros_like(prec)\n",
    "Q10 = np.zeros_like(prec)\n",
    "Q11= np.zeros_like(prec)\n",
    "\n",
    "LZ= np.zeros_like(prec)\n",
    "QLZ = np.zeros_like(prec)\n",
    "Qsim= np.zeros_like(prec)\n",
    "Qin= np.zeros_like(prec)\n",
    "Qdir = np.zeros_like(prec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "64dbeb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining initial states\n",
    "SN[0] = 50  # initial value for the simulated snow pack # Initial snow state\n",
    "SW[0] = 20  # inital liquid water in the snow pack\n",
    "\n",
    "SM[0]=  50.0 # initial soil moisture\n",
    "UZ[0] = 20.0 # Initial upper storage\n",
    "LZ[0] = 10.0 # Initial lower storage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e7d4f8",
   "metadata": {},
   "source": [
    "## HBV Routine computations"
   ]
  },
  {
   "cell_type": "raw",
   "id": "abebfbef",
   "metadata": {},
   "source": [
    "#np.where is used to compute multiple conditions\n",
    "np.where(condition1 & condition2, arr, 0)\n",
    "kwarg 1- condition\n",
    "arr- return arr\n",
    "0- value in arr if the condition is False\n",
    "\n",
    "#Numpy minimum \n",
    "Does element-wise calculation for entire array \n",
    "np.minimum and np.maximum functions are used to find the element-wise minimum and maximum, respectively. \n",
    "\n",
    "#Working with masked array, put array in the end #order of computation when working with np.masked arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "da3ed590",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, len(prec)):\n",
    "    #np.where is used to compute multiple conditions\n",
    "    \n",
    "    #Getting rain and snow precipitation\n",
    "    Prain[i]= np.where(temp[i]>Tx, prec[i]*Pcorr,0)\n",
    "    Psnow[i]= np.where(temp[i]<=Tx, prec[i]*Scorr,0)\n",
    "    \n",
    "    #Snow routine\n",
    "    # Snow melt equation \n",
    "    SMLT[i]= np.minimum(SN[i-1], np.maximum(0, CX*(temp[i]-Ts)))  #to ensure we dont melt more snow that available and also avoid negative melt\n",
    "\n",
    "    # Snow refreeze\n",
    "    SR[i]= np.minimum(SW[i-1], np.maximum(0,-1*CFR*CX*(temp[i]-Ts))) #Refreeze doesnt exceed the liquid water in the snow pack\n",
    "\n",
    "    ST[i]= (SN[i-1]+Psnow[i]) *CPRO  # Computed free water limit in the snow pack\n",
    "\n",
    "    #computing new states for the model\n",
    "    SN[i] = SN[i-1]+ Psnow[i]-SMLT[i] + SR[i]  # Dry snow\n",
    "    SW[i]= np.minimum(ST[i], SW[i-1]+ Prain[i]+SMLT[i]-SR[i])# Water content in snow\n",
    "    \n",
    "    \n",
    "    #In Soil\n",
    "    #All excess water from the snow is sent to the soil routine\n",
    "    Qin[i]= np.maximum(0, (SW[i-1]+ Prain[i]+SMLT[i]-SR[i])-ST[i])\n",
    "\n",
    "    #Direct runoff if the infilttration of soil is exceeded\n",
    "    Qdir[i] = np.maximum(0, SM[i-1]+Qin[i]-FC)\n",
    "    INSOIL[i]= Qin[i]-Qdir[i]\n",
    "    \n",
    "    #Soil routine \n",
    "    dUZ[i]= INSOIL[i]*(SM[i-1]/FC)**Beta  # water to the upper zone\n",
    "    \n",
    "    EA[i]= evap[i]*np.minimum(1, SM[i-1]/LP)  # Actual Evapouration\n",
    "    SM[i] = SM[i-1]+ INSOIL[i]-dUZ[i]-EA[i] # Soil water content\n",
    "    \n",
    "    \n",
    "    #Upper Zone routine\n",
    "    #we add direct runoff to water infiltrated from the soil\n",
    "    #NB if UZ <Perc; reduce perc according\n",
    "\n",
    "    Q10[i]= np.minimum((UZ[i-1]+ dUZ[i]+Qdir[i]-np.minimum(PERC,UZ[i-1])), UZ1)*K1\n",
    "\n",
    "    Q11[i]= np.maximum(0, (UZ[i-1]+ dUZ[i]+Qdir[i]-np.minimum(PERC,UZ[i-1]))-UZ1)*K2\n",
    "    UZ[i] = UZ[i-1]+ dUZ[i]+Qdir[i]-np.minimum(PERC,UZ[i-1])- Q10[i]-Q11[i]\n",
    "\n",
    "    #Lower zone routine\n",
    "    QLZ[i] = KLZ*(LZ[i-1]+np.minimum(PERC,UZ[i-1]))+ LA*(prec[i]-evap[i])*KLZ\n",
    "    \n",
    "    \n",
    "    #LZ[i]= LZ[i-1]+ np.minimum(PERC,UZ[i-1]) + (prec[i]-evap[i])*LA - QLZ[i]\n",
    "    #LZ[i]= LZ[i-1]+ np.minimum(PERC,UZ[i-1])- QLZ[i] + LA*(prec[i]-evap[i])\n",
    "    \n",
    "    LZ[i]= np.maximum(0, (LZ[i-1]+ np.minimum(PERC,UZ[i-1])- QLZ[i] + LA*(prec[i]-evap[i])))\n",
    "    \n",
    "   \n",
    "    #simulated discharge\n",
    "    \n",
    "    Qsim[i]= (Q10[i]+Q11[i]+ QLZ[i])*(Area*10**3)/(86400)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "10a0fdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting coordinates \n",
    "lat= ds_oul['lat'].to_numpy()\n",
    "lon= ds_oul['lon'].to_numpy()\n",
    "time= ds_oul['time'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2bcaf0",
   "metadata": {},
   "source": [
    "### From numpy array to xarray \n",
    "\n",
    "### Here create different variable outputs from the model routines "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ae89f30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Simulated Discharges \n",
    "Qsim_dr= xr.DataArray(Qsim,\n",
    "                      coords={'time':time, 'lat':lat, 'lon':lon},\n",
    "                     dims=['time','lat', 'lon'])\n",
    "\n",
    "# Snow distribution\n",
    "Qsn_dr= xr.DataArray(SN,\n",
    "                      coords={'time':time, 'lat':lat, 'lon':lon},\n",
    "                     dims=['time','lat', 'lon'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2f0a2b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spatial_agg(cm):\n",
    "    weights = np.cos(np.deg2rad(cm.lat))\n",
    "    weights.name= 'weights'\n",
    "    cm_weighted= cm.weighted(weights)\n",
    "    cm_agg = cm_weighted.mean(['lat','lon'])\n",
    "    \n",
    "    return cm_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fecb801",
   "metadata": {},
   "source": [
    "##  Sub-catchment discharges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c78e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of shapefiles and corresponding labels\n",
    "shapefiles = [shp1, shp2, shp3, shp4]\n",
    "labels = [\"Subcat1\", \"Subcat2\", \"Subcat3\",\"Subcat4\" ]  # Adjust labels as needed\n",
    "\n",
    "# Create a dictionary to store the results\n",
    "Qsim = {}\n",
    "\n",
    "# Loop through the shapefiles and apply the clip2 function\n",
    "for i, shp in enumerate(shapefiles):\n",
    "    label = labels[i] if i < len(labels) else f\"Region_{i+1}\"\n",
    "    Qsim[label] = clip2(Qsim_dr, shp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "315bd886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0R Getting  discharges \n",
    "\n",
    "Qsim1= clip2(Qsim_dr, shp1) \n",
    "Qsim2= clip2(Qsim_dr, shp2)\n",
    "\n",
    "Qsim3= clip2(Qsim_dr, shp3) \n",
    "Qsim4= clip2(Qsim_dr, shp4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e71fa6",
   "metadata": {},
   "source": [
    "## Spatial aggregation\n",
    "### To Data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "562a4c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sub catchment discharge\n",
    "def qsim(qsim_ds):\n",
    "    q_arr= qsim_ds.to_numpy()\n",
    "    q_arr2= ma.masked_invalid(q_arr)\n",
    "    \n",
    "    qsum= np.sum(q_arr2,axis=(1,2))\n",
    "    df_q= pd.DataFrame(qsum)\n",
    "    \n",
    "    df_q= pd.DataFrame(qsum, index=time)\n",
    "    df_q.rename(columns={0:'Qsim'}, inplace=True)\n",
    "    \n",
    "    df_q= df_q.rename_axis('Date')\n",
    "\n",
    "    #df_q.index= time\n",
    "    \n",
    "    return df_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d4df5742",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_q1= qsim(Qsim1) #Subcat 1\n",
    "df_q2= qsim(Qsim2) #Subcat 2\n",
    "\n",
    "df_q3= qsim(Qsim3) #Subcat 3\n",
    "df_q4= qsim(Qsim4) #Subcat 4\n",
    "\n",
    "# Concatenating DataFrames while handling similar column names\n",
    "df_simq = pd.concat([df_q1, df_q3,df_q4], axis=1, \n",
    "                    keys=['Subcat1','Subcat2','Subcat3','Subcat4'])\n",
    "\n",
    "# Flatten MultiIndex columns if necessary\n",
    "df_simq.columns = df_simq.columns.droplevel(1)\n",
    "\n",
    "\n",
    "# Flatten MultiIndex columns if necessary\n",
    "df_simq.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d098f04",
   "metadata": {},
   "source": [
    "# River routing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf19667",
   "metadata": {},
   "source": [
    "## Kinewatic wave routing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59594b6f",
   "metadata": {},
   "source": [
    "**A kinematic wave** is an approximation to the one-dimensional St.Venant equations \n",
    "(https://en.wikipedia.org/wiki/Shallow_water_equations ) that is used quite a lot in hydrology to \n",
    "describe overland flow in distributed and semi-distributed models. The simplified equations can be \n",
    "described like this (assuming lateral flow = 0): \n",
    "\n",
    "$$\n",
    "Q_{i+1}^{j+1} =\n",
    "\\frac{\\left[\\frac{\\Delta t}{\\Delta x} \\, Q_i^{j+1} \\;+\\; \\alpha \\,\\beta \\,\\Bigl(\\frac{Q_i^j + Q_{i+1}^j}{2}\\Bigr)^{\\beta - 1}\\right]}\n",
    "{\\left[\\frac{\\Delta t}{\\Delta x} \\;+\\; \\alpha \\,\\beta \\,\\Bigl(\\frac{Q_i^j + Q_{i+1}^j}{2}\\Bigr)^{\\beta - 1}\\right]}\n",
    "$$\n",
    "\n",
    "where **a**, **b** are coefficients, \n",
    "**Q** is the discharge,\n",
    "\n",
    "**i** is the space dimension and **j** is the time dimension. \n",
    "The two coefficients are derived from the Manning equation and has the form: \n",
    "\n",
    "**B** – channel width, \n",
    "\n",
    "**M** – Mannings number,\n",
    "\n",
    "**S** – channel slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337f131d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simulated sub basin\n",
    "df_simq\n",
    "\n",
    "# File containing the coordinates and draining basin \n",
    "df_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bca792",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the elevation at sub-basin outlet\n",
    "coord_arr= df_coordinates.to_numpy()\n",
    "\n",
    "coord_dem =[]\n",
    "for i in range(len(coord_arr)):\n",
    "    x= coord_arr[i,0]\n",
    "    y= coord_arr[i,1]\n",
    "    dem_coord= float(dem_oul['elevtn'][0].sel(x= x, y= y, method='nearest').to_numpy())\n",
    "    coord_dem.append(dem_coord)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e9b3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the distance river stretches\n",
    "distance_arr= []\n",
    "for i in range(len(coord_arr)):\n",
    "    index= coord_arr[i,2]-1\n",
    "    distance = float(np.sqrt((coord_arr[i,0]-coord_arr[index,0])**2+(coord_arr[i,1]-coord_arr[index,1])**2))\n",
    "    distance_arr.append(distance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df72362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Routing paramters \n",
    "M= 32 # Mannings M\n",
    "B = 40 # Width in m\n",
    "time_step = 60*60*24 # Daily time step\n",
    "beta= 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8a4793f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coordinates['DEM']= coord_dem\n",
    "df_coordinates['Distance']= distance_arr\n",
    "\n",
    "\n",
    "df_coordinates['Slope']= df_coordinates['DEM']/df_coordinates['Distance']\n",
    "df_coordinates['alpha']= (B**(2/3)/(M*df_coordinates['Slope']**0.5))**0.6\n",
    "df_coordinates['delta']= time_step/df_coordinates['Distance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b211a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_routed = pd.DataFrame()\n",
    "\n",
    "for i in range(len(df_subcat.columns)):\n",
    "    df_routed['Sub'+str(i+1)] = df_subcat.iloc[:,i] # Creating an initial unrouted flow\n",
    "\n",
    "\n",
    "for i in range(1, len(df_subcat)):\n",
    "    #Routing flow from Subcat P1 to Subcat P2 and adding flow at Sub basin flow at Subcat P2\n",
    "    \n",
    "    df_routed['P2'].iloc[i] += (\n",
    "        (df_coordinates.iloc[0, 7] * df_routed['P1'].iloc[i] + df_coordinates.iloc[0, 6] * beta * df_routed['P1'].iloc[i-1] *\n",
    "        ((df_routed['P1'].iloc[i-1] + df_routed['P1'].iloc[i]) / 2)**(beta-1)) /\n",
    "        (df_coordinates.iloc[0, 7] + df_coordinates.iloc[0, 6] *\n",
    "        ((df_routed['P1'].iloc[i-1] + df_routed['P1'].iloc[i]) / 2)**(beta-1))\n",
    "    )\n",
    "    \n",
    "    #Routing flow from P2 and P3 to P4 and adding flow at P4\n",
    "    \n",
    "    df_routed['P4'].iloc[i] += ((\n",
    "        (df_coordinates.iloc[2, 7] * df_routed['P3'].iloc[i] + df_coordinates.iloc[2, 6] * beta * df_routed['P3'].iloc[i-1] *\n",
    "        ((df_routed['P3'].iloc[i-1] + df_routed['P3'].iloc[i]) / 2)**(beta-1)) /\n",
    "        (df_coordinates.iloc[2, 7] + df_coordinates.iloc[2, 6] *\n",
    "        ((df_routed['P3'].iloc[i-1] + df_routed['P3'].iloc[i]) / 2)**(beta-1))\n",
    "    )+ \n",
    "    (\n",
    "        (df_coordinates.iloc[1, 7] * df_routed['P2'].iloc[i] + df_coordinates.iloc[1, 6] * beta * df_routed['P2'].iloc[i-1] *\n",
    "        ((df_routed['P2'].iloc[i-1] + df_routed['P2'].iloc[i]) / 2)**(beta-1)) /\n",
    "        (df_coordinates.iloc[1, 7] + df_coordinates.iloc[1, 6] *\n",
    "        ((df_routed['P2'].iloc[i-1] + df_routed['P2'].iloc[i]) / 2)**(beta-1))\n",
    "    ))\n",
    "    \n",
    "df_routed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21a1772",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "climate",
   "language": "python",
   "name": "climate"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
