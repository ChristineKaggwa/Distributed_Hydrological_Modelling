{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ede1f43",
   "metadata": {},
   "source": [
    "# DISTRIBUTED HBV MODEL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b283d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "#Working with masked array\n",
    "import numpy.ma as ma\n",
    "import math\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d65e285",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import rasterio\n",
    "import rioxarray\n",
    "#Projecting the files\n",
    "import cartopy.crs as ccrs  # projection\n",
    "\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, LineString, Polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967c26cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Library to compute flow directions\n",
    "import datetime\n",
    "from datetime import date\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5065b9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cliping netcdf file\n",
    "\n",
    "from shapely.geometry import mapping\n",
    "import geopandas as gpd  #for reading the shapefile\n",
    "import regionmask  #For masking dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29019c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sub catchment discharge\n",
    "def qsim(qsim_ds,time):\n",
    "    q_arr= qsim_ds.to_numpy()\n",
    "    q_arr2= ma.masked_invalid(q_arr)\n",
    "    \n",
    "    qsum= np.sum(q_arr2,axis=(1,2))\n",
    "    #df_q= pd.DataFrame(qsum)\n",
    "    \n",
    "    df_q= pd.DataFrame(qsum, index=time)\n",
    "    df_q.rename(columns={0:'Qsim'}, inplace=True)\n",
    "    \n",
    "    df_q= df_q.rename_axis('Date')\n",
    "\n",
    "    #df_q.index= time\n",
    "    \n",
    "    return df_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0beb016",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxbas_weights(maxbas):\n",
    "    mb = int(np.ceil(maxbas))\n",
    "    w = np.zeros(mb)\n",
    "    t = np.arange(1, mb+1)\n",
    "    for i in range(mb):\n",
    "        if t[i] < maxbas / 2:\n",
    "            w[i] = t[i] / (maxbas / 2)\n",
    "        else:\n",
    "            w[i] = (maxbas - t[i] + 1) / (maxbas / 2)\n",
    "    w /= w.sum()\n",
    "    return w\n",
    "\n",
    "def apply_maxbas_routing(runoff, maxbas):\n",
    "    weights = maxbas_weights(maxbas)\n",
    "    routed = np.convolve(runoff, weights, mode='full')[:len(runoff)]\n",
    "    return routed\n",
    "\n",
    "def qsim_routed(qsim_ds, time, maxbas):\n",
    "    \"\"\"\n",
    "    maxbas: parameter for triangular weighting/routing\n",
    "    \"\"\"\n",
    "    q_arr = qsim_ds.to_numpy()\n",
    "    q_arr2 = ma.masked_invalid(q_arr)\n",
    "    qsum = np.sum(q_arr2, axis=(1,2))\n",
    "    \n",
    "    # Apply maxbas routing (HBV triangular convolution)\n",
    "    qsum_routed = apply_maxbas_routing(qsum, maxbas)\n",
    "    \n",
    "    df_q = pd.DataFrame(qsum_routed, index=time)\n",
    "    df_q.rename(columns={0:'Qsim'}, inplace=True)\n",
    "    df_q = df_q.rename_axis('Date')\n",
    "    \n",
    "    return df_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72357b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qobs= pd.read_excel(r\"Discharge series.xlsx\", index_col=0,parse_dates= True)\n",
    "df_qobs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a06705",
   "metadata": {},
   "source": [
    "# A.1 Subcatchments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3dddf5",
   "metadata": {},
   "source": [
    "# Reading shape files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295816c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "shp1= gpd.read_file(r\"subbasin1.shp\")\n",
    "shp2= gpd.read_file(r\"subbasin2.shp\")\n",
    "shp3= gpd.read_file(r\"subbasin3.shp\")\n",
    "shp4= gpd.read_file(r\"subbasin4.shp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e92da0",
   "metadata": {},
   "source": [
    "# Creating a function to define a subbasin dem:\n",
    "def subbasin_clip(dem_cat, shp):\n",
    "    dem_sub= raster.rio.clip(shp.geometry.apply(mapping), shp.crs, all_touched= True, drop= True)\n",
    "    return dem_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c9b8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip2(cm, shp):\n",
    "    cm = cm.rename({'lat':'y', 'lon':'x'}) # Specifiying the coordinate system\n",
    "    cm.rio.write_crs(\"EPSG:3067\",inplace= True)\n",
    "    \n",
    "    #cm_fin= cm.rio.clip(shp.geometry.apply(mapping), shp.crs, all_touched= True, drop= True)\n",
    "    cm_fin= cm.rio.clip(shp.geometry.apply(mapping), shp.crs)\n",
    "    \n",
    "    cm_fin= cm_fin.rename({'y':'lat', 'x':'lon'})\n",
    "    return cm_fin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce78dc51",
   "metadata": {},
   "source": [
    "# B. HBV ROUTINE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e525d90d",
   "metadata": {},
   "source": [
    "### Climate forcing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a570b9c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Input data\n",
    "ds_temp= xr.open_dataset(r\"DailyTemp.nc\")\n",
    "ds_prec = xr.open_dataset(r\"DailyPrec.nc\")\n",
    "ds_evap= xr.open_dataset(r\"DailyEvap.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf67ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ds= ds_prec\n",
    "#Creating arrays\n",
    "prec= np.array(ds_prec.pr)\n",
    "temp= np.array(ds_temp.tas)\n",
    "evap= np.array(ds_evap.ET0) \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5378b45a",
   "metadata": {},
   "source": [
    "## B.1 HBV Routine computations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9390b1d4",
   "metadata": {},
   "source": [
    "### Abbreviation definitions\n",
    "\n",
    "- PCORR     Precipitation correction (usually around 1.05) \n",
    "- SCORR     Snow correction (usually around 1.2) \n",
    "- TCGRAD    Temperature lapse rate dry day (degree/100 m) \n",
    "- TPGRAD    Temperature lapse rate wet day (degree/100 m) \n",
    "- PGRAD      Precipitation lapse rate (%/100 m) \n",
    "\n",
    "#### Snow routine States and Parameters \n",
    "- SN     Dry snow (mm) \n",
    "- SW     Water content in snow (mm)\n",
    "- SWE    Snow water equivalent\n",
    "\n",
    "\n",
    "- SMLT    Computed snow melt (mm) \n",
    "- SR      Computed refrozen water (mm) \n",
    "- ST      Computed free water limit in the snow pack (mm) \n",
    "- INSOIL  Computed water going to the soil routine (mm) \n",
    "\n",
    "\n",
    "- TX     Transition temperature snow â€“ rain (deg.C) \n",
    "- TS     Boundary temperature for snowmelt (deg.C) \n",
    "- CX     Degree day factor (mm/deg.C * day) \n",
    "- CFR    Refreeze factor (mm/deg.C * day) \n",
    "- CPRO   Liquid water content in snow (%) \n",
    "- CXN    Degree day factor in forested areas (PINEHBV) \n",
    "- TSN    Boundary temperature in forested areas (PINEHBV)\n",
    "\n",
    "#### Soil routine States and Parameters\n",
    "\n",
    "- SM    Soil moisture content (mm) \n",
    "\n",
    "- EA     Actual evaporation (mm) \n",
    "- dUZ    Water to upper zone (mm)  \n",
    "\n",
    "- FC    Field capacity (mm) \n",
    "- Beta  Exponent in function defining storage and output (-) \n",
    "- LP    Boundary for full evaporation (0-1) \n",
    "\n",
    "- UZ    Water content in upper zone (mm) \n",
    "- Q11   Runoff from upper outlet (mm) \n",
    "- Q10   Runoff from lower outlet (mm) \n",
    "\n",
    "#### Upper and Lower States and Parameters\n",
    "\n",
    "- KUZ1  Upper outlet constant (-) \n",
    "- KUZ  Lower outlet constant (-) \n",
    "- UZ1  Treshold for activation of upper outlet (mm) \n",
    "- PERC  Percolation, water transport from upper to lower zone (mm) \n",
    "\n",
    "- Note that KUZ1 is always lager than KUZ.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3ed590",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hbv_model(params,params2, prec, temp, evap, ds_oul):\n",
    "    # Model parameters: [Pcorr, Scorr, Tx, Ts, Cx  FC, Beta, LP, K1, K2,UZ1, KLZ, PERC]\n",
    "    Pcorr, Scorr, Tx, Ts, CX, FC, Beta, LP, K1, K2, UZ1, KLZ, PERC = params\n",
    "    \n",
    "    #Free parameters\n",
    "    Pgrad, Tgrad, Area, CFR, CFRO, LA= params2\n",
    "\n",
    "    #creating empty array for the different states \n",
    "    #Defining the snow routine\n",
    "\n",
    "    SN=  np.zeros_like(prec) #Dry snow pack\n",
    "    Prain= np.zeros_like(prec) # Precipitation as Rain\n",
    "    Psnow= np.zeros_like(prec) # Precipitation as snow\n",
    "    SMLT= np.zeros_like(prec) #Snow melt \n",
    "    SR= np.zeros_like(prec) #Refreeze\n",
    "    ST=  np.zeros_like(prec)#Free water in the snow pack\n",
    "    INSOIL= np.zeros_like(prec) # To the soil routine\n",
    "    SW= np.zeros_like(prec) # Liquid water in snow\n",
    "\n",
    "    #Defining the soil routine \n",
    "    dUZ= np.zeros_like(prec)\n",
    "    EA = np.zeros_like(prec)\n",
    "    SM= np.zeros_like(prec)\n",
    "\n",
    "\n",
    "    #Defining the upper tank and lower tank routines\n",
    "    #Upper tank\n",
    "    UZ= np.zeros_like(prec)\n",
    "    Q10 = np.zeros_like(prec)\n",
    "    Q11= np.zeros_like(prec)\n",
    "\n",
    "    LZ= np.zeros_like(prec)\n",
    "    QLZ = np.zeros_like(prec)\n",
    "    Qsim= np.zeros_like(prec)\n",
    "    Qin= np.zeros_like(prec)\n",
    "    Qdir = np.zeros_like(prec)\n",
    "\n",
    "\n",
    "\n",
    "    #Defining initial states\n",
    "    SN[0] = 17  # initial value for the simulated snow pack # Initial snow state\n",
    "    SW[0] = 17  # inital liquid water in the snow pack\n",
    "\n",
    "    SM[0]=  20.0 # initial soil moisture\n",
    "    UZ[0] = 20.0 # Initial upper storage\n",
    "    LZ[0] = 10.0 # Initial lower storage\n",
    "\n",
    "\n",
    "    ## HBV Vertical routine\n",
    "\n",
    "\n",
    "    #LA= lake_arr.copy()\n",
    "    for i in range(1, len(prec)):\n",
    "        #Getting rain and snow precipitation\n",
    "        Prain[i]= np.where(temp[i]>Tx, prec[i]*Pcorr,0)\n",
    "        Psnow[i]= np.where(temp[i]<=Tx, prec[i]*Scorr,0)\n",
    "\n",
    "        #Snow routine\n",
    "        # Snow melt equation \n",
    "        SMLT[i]= np.minimum(SN[i-1], np.maximum(0, CX*(temp[i]-Ts)))  #to ensure we dont melt more snow that available and also avoid negative melt\n",
    "\n",
    "        # Snow refreeze\n",
    "        SR[i]= np.minimum(SW[i-1], np.maximum(0,-1*CFR*CX*(temp[i]-Ts))) #Refreeze doesnt exceed the liquid water in the snow pack\n",
    "\n",
    "        ST[i]= (SN[i-1]+Psnow[i]) *CFRO  # Computed free water limit in the snow pack\n",
    "\n",
    "        #computing new states for the model\n",
    "        SN[i] = SN[i-1]+ Psnow[i]-SMLT[i] + SR[i]  # Dry snow\n",
    "        SW[i]= np.minimum(ST[i], SW[i-1]+ Prain[i]+SMLT[i]-SR[i])# Water content in snow\n",
    "\n",
    "\n",
    "        #In Soil\n",
    "        #All excess water from the snow is sent to the soil routine\n",
    "        Qin[i]= np.maximum(0, (SW[i-1]+ Prain[i]+SMLT[i]-SR[i])-ST[i])\n",
    "\n",
    "        #Direct runoff if the infilttration of soil is exceeded\n",
    "        Qdir[i] = np.maximum(0, SM[i-1]+Qin[i]-FC)\n",
    "        INSOIL[i]= Qin[i]-Qdir[i]\n",
    "\n",
    "        #Soil routine \n",
    "        dUZ[i]= INSOIL[i]*(SM[i-1]/FC)**Beta  # water to the upper zone\n",
    "\n",
    "        EA[i]= evap[i]*np.minimum(1, SM[i-1]/(LP*FC)) # Actual Evapouration\n",
    "        SM[i] = SM[i-1]+ INSOIL[i]-dUZ[i]-EA[i] # Soil water content\n",
    "\n",
    "\n",
    "        #Upper Zone routine\n",
    "\n",
    "        Q10[i]= np.minimum((UZ[i-1]+ dUZ[i]+Qdir[i]-np.minimum(PERC,UZ[i-1])), UZ1)*K1\n",
    "\n",
    "        Q11[i]= np.maximum(0, (UZ[i-1]+ dUZ[i]+Qdir[i]-np.minimum(PERC,UZ[i-1]))-UZ1)*K2\n",
    "        UZ[i] = UZ[i-1]+ dUZ[i]+Qdir[i]-np.minimum(PERC,UZ[i-1])- Q10[i]-Q11[i]\n",
    "\n",
    "        #Lower zone routine\n",
    "        QLZ[i] = KLZ*(LZ[i-1]+np.minimum(PERC,UZ[i-1]))+ LA*(prec[i]-evap[i])*KLZ\n",
    "        LZ[i]= np.maximum(0, (LZ[i-1]+ np.minimum(PERC,UZ[i-1])- QLZ[i] + LA*(prec[i]-evap[i])))\n",
    "\n",
    "\n",
    "        #simulated discharge\n",
    "\n",
    "        Qsim[i]= (Q10[i]+Q11[i]+ QLZ[i])*(Area*10**3)/(86400)\n",
    "\n",
    "\n",
    "    # Extracting coordinates \n",
    "    lat= ds['lat'].to_numpy()\n",
    "    lon= ds['lon'].to_numpy()\n",
    "    time= ds['time'].to_numpy()\n",
    "\n",
    "\n",
    "    #Converting a numpy array to xarray\n",
    "    Qsim_dr= xr.DataArray(Qsim,\n",
    "                          coords={'time':time, 'lat':lat, 'lon':lon},\n",
    "                         dims=['time','lat', 'lon'])\n",
    "\n",
    "    \n",
    "    # to dataset\n",
    "    Qsim_ds= Qsim_dr.to_dataset(name='Q', promote_attrs=True)\n",
    "\n",
    "\n",
    "    #Qsim_dr= Qsim_ds.Q\n",
    "    # Map basin names to their shapefiles (in order)\n",
    "    basins = [\n",
    "        (\"subbasin1\", shp1),\n",
    "        (\"subbasin2\", shp2),\n",
    "        (\"subbasin3\", shp3),\n",
    "        (\"subbasin4\", shp4),\n",
    "        ]\n",
    "\n",
    "    # Build a dict of DataFrames: {name: qsim(clip2(Qsim_dr, shp))}\n",
    "    df_dict = {name: qsim(clip2(Qsim_dr, shp),time) for name, shp in basins}\n",
    "\n",
    "    # Concatenate along columns; collapse the second level if present\n",
    "    df_simq = pd.concat(df_dict, axis=1)\n",
    "\n",
    "    # Flatten MultiIndex columns if necessary\n",
    "    df_simq.columns = df_simq.columns.droplevel(1)\n",
    "    \n",
    "    return df_simq\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fae41d",
   "metadata": {},
   "source": [
    "### HBV model with MAXBAS Routing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc05ffb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hbv_model_maxbas(params,params2, prec, temp, evap, ds_oul):\n",
    "    # Model parameters: [Pcorr, Scorr, Tx, Ts, Cx  FC, Beta, LP, K1, K2,UZ1, KLZ, PERC]\n",
    "    Pcorr, Scorr, Tx, Ts, CX, FC, Beta, LP, K1, K2, UZ1, KLZ, PERC = params\n",
    "    \n",
    "    #Free parameters\n",
    "    Pgrad, Tgrad, Area, CFR, CFRO, LA= params2\n",
    "\n",
    "    #creating empty array for the different states \n",
    "    #Defining the snow routine\n",
    "\n",
    "    SN=  np.zeros_like(prec) #Dry snow pack\n",
    "    Prain= np.zeros_like(prec) # Precipitation as Rain\n",
    "    Psnow= np.zeros_like(prec) # Precipitation as snow\n",
    "    SMLT= np.zeros_like(prec) #Snow melt \n",
    "    SR= np.zeros_like(prec) #Refreeze\n",
    "    ST=  np.zeros_like(prec)#Free water in the snow pack\n",
    "    INSOIL= np.zeros_like(prec) # To the soil routine\n",
    "    SW= np.zeros_like(prec) # Liquid water in snow\n",
    "\n",
    "    #Defining the soil routine \n",
    "    dUZ= np.zeros_like(prec)\n",
    "    EA = np.zeros_like(prec)\n",
    "    SM= np.zeros_like(prec)\n",
    "\n",
    "\n",
    "    #Defining the upper tank and lower tank routines\n",
    "    #Upper tank\n",
    "    UZ= np.zeros_like(prec)\n",
    "    Q10 = np.zeros_like(prec)\n",
    "    Q11= np.zeros_like(prec)\n",
    "\n",
    "    LZ= np.zeros_like(prec)\n",
    "    QLZ = np.zeros_like(prec)\n",
    "    Qsim= np.zeros_like(prec)\n",
    "    Qin= np.zeros_like(prec)\n",
    "    Qdir = np.zeros_like(prec)\n",
    "\n",
    "\n",
    "\n",
    "    #Defining initial states\n",
    "    SN[0] = 17  # initial value for the simulated snow pack # Initial snow state\n",
    "    SW[0] = 17  # inital liquid water in the snow pack\n",
    "\n",
    "    SM[0]=  20.0 # initial soil moisture\n",
    "    UZ[0] = 20.0 # Initial upper storage\n",
    "    LZ[0] = 10.0 # Initial lower storage\n",
    "\n",
    "\n",
    "    ## HBV Vertical routine\n",
    "\n",
    "\n",
    "    #LA= lake_arr.copy()\n",
    "    for i in range(1, len(prec)):\n",
    "        #np.where is used to compute multiple conditions\n",
    "\n",
    "        #Getting rain and snow precipitation\n",
    "        Prain[i]= np.where(temp[i]>Tx, prec[i]*Pcorr,0)\n",
    "        Psnow[i]= np.where(temp[i]<=Tx, prec[i]*Scorr,0)\n",
    "\n",
    "        #Snow routine\n",
    "        # Snow melt equation \n",
    "        SMLT[i]= np.minimum(SN[i-1], np.maximum(0, CX*(temp[i]-Ts)))  #to ensure we dont melt more snow that available and also avoid negative melt\n",
    "\n",
    "        # Snow refreeze\n",
    "        SR[i]= np.minimum(SW[i-1], np.maximum(0,-1*CFR*CX*(temp[i]-Ts))) #Refreeze doesnt exceed the liquid water in the snow pack\n",
    "\n",
    "        ST[i]= (SN[i-1]+Psnow[i]) *CFRO  # Computed free water limit in the snow pack\n",
    "\n",
    "        #computing new states for the model\n",
    "        SN[i] = SN[i-1]+ Psnow[i]-SMLT[i] + SR[i]  # Dry snow\n",
    "        SW[i]= np.minimum(ST[i], SW[i-1]+ Prain[i]+SMLT[i]-SR[i])# Water content in snow\n",
    "\n",
    "\n",
    "        #In Soil\n",
    "         Qin[i]= np.maximum(0, (SW[i-1]+ Prain[i]+SMLT[i]-SR[i])-ST[i])\n",
    "\n",
    "        #Direct runoff if the infilttration of soil is exceeded\n",
    "        Qdir[i] = np.maximum(0, SM[i-1]+Qin[i]-FC)\n",
    "        INSOIL[i]= Qin[i]-Qdir[i]\n",
    "\n",
    "        #Soil routine \n",
    "        dUZ[i]= INSOIL[i]*(SM[i-1]/FC)**Beta  # water to the upper zone\n",
    "\n",
    "        EA[i]= evap[i]*np.minimum(1, SM[i-1]/(LP*FC)) # Actual Evapouration\n",
    "        SM[i] = SM[i-1]+ INSOIL[i]-dUZ[i]-EA[i] # Soil water content\n",
    "\n",
    "\n",
    "        #Upper Zone routine\n",
    "        Q10[i]= np.minimum((UZ[i-1]+ dUZ[i]+Qdir[i]-np.minimum(PERC,UZ[i-1])), UZ1)*K1\n",
    "\n",
    "        Q11[i]= np.maximum(0, (UZ[i-1]+ dUZ[i]+Qdir[i]-np.minimum(PERC,UZ[i-1]))-UZ1)*K2\n",
    "        UZ[i] = UZ[i-1]+ dUZ[i]+Qdir[i]-np.minimum(PERC,UZ[i-1])- Q10[i]-Q11[i]\n",
    "\n",
    "        #Lower zone routine\n",
    "        QLZ[i] = KLZ*(LZ[i-1]+np.minimum(PERC,UZ[i-1]))+ LA*(prec[i]-evap[i])*KLZ\n",
    "        LZ[i]= np.maximum(0, (LZ[i-1]+ np.minimum(PERC,UZ[i-1])- QLZ[i] + LA*(prec[i]-evap[i])))\n",
    "\n",
    "\n",
    "        #simulated discharge\n",
    "\n",
    "        Qsim[i]= (Q10[i]+Q11[i]+ QLZ[i])*(Area*10**3)/(86400)\n",
    "\n",
    "\n",
    "    # Extracting coordinates \n",
    "    lat= ds['lat'].to_numpy()\n",
    "    lon= ds['lon'].to_numpy()\n",
    "    time= ds['time'].to_numpy()\n",
    "\n",
    "\n",
    "    #Converting a numpy array to xarray\n",
    "    Qsim_dr= xr.DataArray(Qsim,\n",
    "                          coords={'time':time, 'lat':lat, 'lon':lon},\n",
    "                         dims=['time','lat', 'lon'])\n",
    "\n",
    "   \n",
    "    Qsim_ds= Qsim_dr.to_dataset(name='Q', promote_attrs=True)\n",
    "    \n",
    "    basins_area = [\n",
    "            (\"subbasin1\", shp1,3109),\n",
    "            (\"subbasin2\", shp2,1630),\n",
    "            (\"subbasin3\", shp3,297),\n",
    "            (\"subbasin4\", shp4,2215),\n",
    "            ]\n",
    "\n",
    "    # Build a dict of DataFrames\n",
    "    df_dict_r = {name: qsim_routed(clip2(Qsim_dr, shp),time,(area/450)) for name, shp, area,in basins_area}\n",
    "\n",
    "    # Concatenate along columns;\n",
    "    df_simq_r = pd.concat(df_dict_r, axis=1)\n",
    "\n",
    "    # Flatten MultiIndex columns\n",
    "    df_simq_r.columns = df_simq_r.columns.droplevel(1)\n",
    "    \n",
    "    return df_simq_r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a0fdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initial guess for paramaters\n",
    "     #Pcorr, Scorr, Tx, Ts, CX, FC, Beta, LP, K1, K2, UZ1, KLZ, PERC\n",
    "initial_params= [1,1, -0.36, 1.15, 2.654,61.8, 4.5, 0.8, 0.022, 0.06, 82, 0.007, 0.65]\n",
    "\n",
    "\n",
    "#Free parameters\n",
    "#Pgrad, Tgrad, Area, CFR, CFRO, LA= params2\n",
    "free_params= [0.65,0.5, 25, 0.01, 0.1, 0.138]\n",
    "\n",
    "\n",
    "#Bounds for  model parameters\n",
    "bounds =[(1,1), (1,1), (-1.5,1.5), (-1.5,1.5), (1.5,4.0), (50,100), (1,6),\n",
    "        (0.75, 0.85), (0.01, 0.045), (0.045, 0.1), (40,100), (0.003, 0.01), (0.1,1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f98602",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the model:\n",
    "\n",
    "\n",
    "df_simq= hbv_model(params=initial_params,\n",
    "                                params2=free_params,\n",
    "                                prec= prec, \n",
    "                                temp= temp, \n",
    "                                evap= evap,\n",
    "                                ds=ds)\n",
    "df_simq.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa63c980",
   "metadata": {},
   "source": [
    "### With MAXBIAS Routing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60cff37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the model:\n",
    "initial_params= [1,1, -0.36, 1.15, 2.654,61.8, 4.5, 0.8, 0.022, 0.06,82, 0.0085, 0.65]\n",
    "df_simq_r= hbv_model_maxbas(params=initial_params,\n",
    "                                params2=free_params,\n",
    "                                prec= prec, \n",
    "                                temp= temp, \n",
    "                                evap= evap,\n",
    "                                ds=ds)\n",
    "df_simq_r.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0108b872",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "climate",
   "language": "python",
   "name": "climate"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
